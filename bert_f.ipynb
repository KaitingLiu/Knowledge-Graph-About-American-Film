{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTiUsjV5-Nf0",
        "outputId": "8c1f1e57-9849-4444-c74f-d6347743404c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 60.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suM-xucptE0g"
      },
      "source": [
        "# 代码复现\n",
        "https://github.com/terrifyzhao/spo_extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vTtWKjhJtD9e"
      },
      "outputs": [],
      "source": [
        "## train 代码\n",
        " \n",
        "import json\n",
        "from tqdm import tqdm   # 进度条\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, AdamW\n",
        "import torch\n",
        "# from model import ObjectModel, SubjectModel\n",
        " \n",
        "GPU_NUM = 0\n",
        " \n",
        "#device = torch.device(f'cuda:{GPU_NUM}') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device = torch.device('cpu')\n",
        " \n",
        "vocab = {}\n",
        "with open('vocab.txt')as file:  # 使用with open 的方法读取词典\n",
        "    for l in file.readlines():\n",
        "        vocab[len(vocab)] = l.strip() # 根据key读取词典\n",
        " \n",
        " \n",
        "def load_data(filename):  # 中文解码加载数据\n",
        "    \"\"\"加载数据\n",
        "    单条格式：{'text': text, 'spo_list': [[s, p, o]]}\n",
        "    \"\"\"\n",
        "    with open(filename) as f:\n",
        "        json_list = json.load(f)\n",
        "    return json_list[:1000]\n",
        " \n",
        " \n",
        "# 加载数据集\n",
        "train_data = load_data('train_5494.json')\n",
        "valid_data = load_data('dev_clean.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVipT19ZpUIa",
        "outputId": "ed93e977-99ac-4e12-9add-7e721adb8067"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'text': 'My Man Godfrey is a 1936 American screwball comedy film directed by Gregory La Cava and starring William Powell and Carole Lombard, who had been briefly married years before appearing together in the film.',\n",
              "  'spo_list': [['My Man Godfrey', 'act', 'William Powell']]},\n",
              " 1000,\n",
              " {'text': 'Stagecoach War is a 1940 American Western film directed by Lesley Selander, written by Norman Houston and Harry F. Olmsted, and starring William Boyd, Russell Hayden, Julie Carter, Harvey Stephens, J. Farrell MacDonald, Britt Wood and Rad Robinson.',\n",
              "  'spo_list': [['Stagecoach War', 'act', 'Rad Robinson']]},\n",
              " 112)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_data[85],len(train_data),valid_data[85],len(valid_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "4e8711a38d3d4ae2b35ec613fe972e2e",
            "cf34fa824ce64d5999133343ba62ea66",
            "27d477826ea140719eb8ea49145df51c",
            "6dcfbb9bd779494cb56e1346d81d5615",
            "f0fb12094dfe4423a7d12d63851c75cc",
            "effd34550bfa4877b86d2d5b0ce34cfd",
            "43130e7494794f7aac971b552d5f0fb9",
            "aab64068135742489aba372ed397c46f",
            "91f7e048b2084c2e9479f7319908ba8e",
            "68293bef8a8548c9bb60320c6c1bab7a",
            "e71e3e887e834d5a8a26c8d823233c02",
            "6586bae032a94d00a8f48a4cf3ce4eaa",
            "ae6314599b00412ab284259ba55c4b05",
            "cd86d37125604c1eb38fe64e29736584",
            "3bacf3b5dbf8422d868276907a9139ad",
            "33fbe4b2453e4c9aaa0dfb4feaf5fed4",
            "cef90620cf284ae4a8e4f4d1f6a69ddb",
            "1e23d8f7b1ae4aae9907162ca85d0cbb",
            "2233387d6ec84410b0bec8c19d8d66ab",
            "c5a872f02c0e4d7bbe3bd9ac718687b0",
            "e8f387414dc14e94ad1a89ba50543403",
            "d8b60da1468844ee8d9be8a4aa18cdf7",
            "2df4c8772ec2431a8554cd9583ff144a",
            "1cf1008992ba4350a93c0995a97cdb1f",
            "568a567f1d5e4e5d8561ea43dbcd1f02",
            "8d8865ad3e904e64afbbc2edf2c831d6",
            "f3acc7f024264402abc06f977e641f88",
            "791ef16d84e249429ae4339efbe4c302",
            "90b13cafd43845b3af9d7e49f82b3786",
            "d5ea0f2379274045be5b6a8e4a7b9c12",
            "0bb5e411475248278de06318149834cb",
            "3cb2aa2043314b8a80b987ce3018a57f",
            "5d8c20a381d84d33a642dc924e640888"
          ]
        },
        "id": "RRkjL5PQtRAz",
        "outputId": "6bdfefe1-0706-4ead-b62c-8c8f1e581fda"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e8711a38d3d4ae2b35ec613fe972e2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6586bae032a94d00a8f48a4cf3ce4eaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2df4c8772ec2431a8554cd9583ff144a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")   # 调用分词器\n",
        " \n",
        "with open('schemas.json') as f: # 读取predicate\n",
        "    json_list = json.load(f)\n",
        "    id2predicate = json_list[0]\n",
        "    predicate2id = json_list[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht5B7GwspjZ_",
        "outputId": "fa459169-5cd4-4c33-ace3-a632904f8d3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'0': 'unknown', '1': 'direct', '2': 'act', '3': 'star'},\n",
              " {'unknown': 0, 'direct': 1, 'act': 2, 'star': 3},\n",
              " 4,\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "id2predicate,predicate2id,len(id2predicate),len(predicate2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9NoQ8aUFKMRO"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertPreTrainedModel\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class SubjectModel(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.dense = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        # print(output)\n",
        "        subject_out = self.dense(output[0])\n",
        "        subject_out = torch.sigmoid(subject_out)\n",
        "        # print(\"subject shape\")\n",
        "        # test = torch.sum(subject_out, dim=1)\n",
        "        # print(test.shape, test)\n",
        "        # print(subject_out)\n",
        "\n",
        "        return output[0], subject_out\n",
        "\n",
        "\n",
        "class ObjectModel(nn.Module):\n",
        "    def __init__(self, subject_model):\n",
        "        super().__init__()\n",
        "        self.encoder = subject_model\n",
        "        self.dense_subject_position = nn.Linear(2, 768)\n",
        "        self.dense_object = nn.Linear(768, 4 * 2)\n",
        "\n",
        "    def forward(self,input_ids,subject_position,attention_mask=None):\n",
        "        # print(\"ObjectModel\")\n",
        "        output, subject_out = self.encoder(input_ids, attention_mask)\n",
        "        # print(output, subject_out)\n",
        "        subject_position = self.dense_subject_position(subject_position).unsqueeze(1)\n",
        "        # print(subject_position)\n",
        "        object_out = output + subject_position\n",
        "        # print(object_out)\n",
        "        # [bs, 768] -> [bs, 98]\n",
        "        object_out = self.dense_object(object_out)\n",
        "        # print(object_out)\n",
        "        # [bs, 98] -> [bs, 4, 2]\n",
        "        object_out = torch.reshape(object_out, (object_out.shape[0], object_out.shape[1], 4, 2))\n",
        "        object_out = torch.sigmoid(object_out)\n",
        "        # print(\"object_out\")\n",
        "        # test = torch.sum(object_out, dim=1)\n",
        "        # print(test.shape, test)\n",
        "        return subject_out, object_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T6-7gMhIe819"
      },
      "outputs": [],
      "source": [
        "def search(pattern, sequence):\n",
        "    \"\"\"从sequence中寻找子串pattern\n",
        "    如果找到，返回第一个下标；否则返回-1。\n",
        "    \"\"\"\n",
        "    n = len(pattern)\n",
        "    for i in range(len(sequence)):\n",
        "        if sequence[i:i + n] == pattern:\n",
        "            return i\n",
        "    return -1\n",
        " \n",
        " \n",
        "def sequence_padding(inputs, length=None, padding=0, mode='post'):\n",
        "    \"\"\"Numpy函数，将序列padding到同一长度\n",
        "    \"\"\"\n",
        "    if length is None:\n",
        "        length = max([len(x) for x in inputs])\n",
        " \n",
        "    pad_width = [(0, 0) for _ in np.shape(inputs[0])]\n",
        "    outputs = []\n",
        "    for x in inputs:\n",
        "        x = x[:length]\n",
        "        if mode == 'post':\n",
        "            pad_width[0] = (0, length - len(x))\n",
        "        elif mode == 'pre':\n",
        "            pad_width[0] = (length - len(x), 0)\n",
        "        else:\n",
        "            raise ValueError('\"mode\" argument must be \"post\" or \"pre\".')\n",
        "        x = np.pad(x, pad_width, 'constant', constant_values=padding)\n",
        "        outputs.append(x)\n",
        " \n",
        "    return np.array(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_HCxxJN9LBC",
        "outputId": "5a090db6-ee43-4421-d65d-14a4bf078474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing SubjectModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing SubjectModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SubjectModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of SubjectModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['dense.bias', 'dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectModel(\n",
              "  (encoder): SubjectModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dense): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              "  (dense_subject_position): Linear(in_features=2, out_features=768, bias=True)\n",
              "  (dense_object): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def data_generator(data, batch_size=3):  #  数据迭代器/数据生成器\n",
        " \n",
        "    batch_input_ids, batch_attention_mask = [], [] #  输出给模型（object）的变量，通过调用bert分词器得到\n",
        "    batch_subject_labels, batch_subject_ids, batch_object_labels = [], [], []\n",
        "    texts = []\n",
        "    for i, d in enumerate(data): #  数据来自dataloader i = 数据索引 d = text\n",
        "        # print(\"______________data_generator___________\") 1 \n",
        "        # print(d)  2\n",
        "        text = d['text'] # 从train 中取出text\n",
        "        texts.append(text)   # text 贴入元组\n",
        "        encoding = tokenizer(text=text) # 使用bert 分词\n",
        "        input_ids, attention_mask = encoding.input_ids, encoding.attention_mask  # 分词后对应“bert词典下标”和mask\n",
        "        # 整理三元组 {s: [(o, p)]}\n",
        "        spoes = {}\n",
        "        for s, p, o in d['spo_list']: # 遍历三元组\n",
        "            # [cls] XXX [sep]\n",
        "            s_encoding = tokenizer(text=s).input_ids[1:-1]  # 将s，o编码成对应的下标\n",
        "            o_encoding = tokenizer(text=o).input_ids[1:-1]  # [1:-1] 去除cls sep\n",
        " \n",
        "            s_idx = search(s_encoding, input_ids) # 从text的input_ids 寻找s的下标\n",
        "            o_idx = search(o_encoding, input_ids) # 从text的input_ids 寻找o的下标\n",
        "            # print(\"s\", s, s_encoding, s_idx) 3\n",
        "            # print(\"o\", o, o_encoding, o_idx) 4\n",
        " \n",
        "            p = predicate2id[p]  # 的到predicate的下标\n",
        " \n",
        "            if s_idx != -1 and o_idx != -1: # 做判断没有反应的返回-1\n",
        "                s = (s_idx, s_idx + len(s_encoding) - 1) # s保存subject的起始位置，起始位置加上长度 -1\n",
        "                o = (o_idx, o_idx + len(o_encoding) - 1, p)# 同上 s,o 是一个元组保存着起始位置和终止位置的下标 以及 p\n",
        "                if s not in spoes:\n",
        "                    spoes[s] = []\n",
        "                spoes[s].append(o) # 将 下标加入 spoes 字典当中去\n",
        "        # print(\"input_ids\", len(input_ids), input_ids) 5\n",
        "        # print(\"spoes:\", spoes) 6\n",
        "        if spoes:\n",
        "            # subject标签\n",
        "            subject_labels = np.zeros((len(input_ids), 2)) # 生成一个input长度的二维向量/ s头s尾\n",
        "            # print(input_ids, subject_labels, subject_labels.shape) 7\n",
        "            for s in spoes:\n",
        "                # 注意要+1，因为有cls符号\n",
        "                subject_labels[s[0], 0] = 1 # 第一行 = ‘0’ 的起始 = s[0] 等于1\n",
        "                subject_labels[s[1], 1] = 1  # 第二行 = ‘1’ 的终止 =s[1] 等于1\n",
        "            # print(\"subject_labels:\", subject_labels) 7\n",
        "            # 一个s对应多个o时，随机选一个subject\n",
        "            start, end = np.array(list(spoes.keys())).T\n",
        "            start = np.random.choice(start)\n",
        "            end = np.random.choice(end[end >= start])\n",
        "            subject_ids = (start, end)\n",
        "            # 对应的object标签\n",
        "            object_labels = np.zeros((len(input_ids), len(predicate2id), 2)) # 序列长度 x predicate长度 x 2\n",
        "            for o in spoes.get(subject_ids, []): # 通过subject 拿出对应的 o\n",
        "                object_labels[o[0], o[2], 0] = 1 # 对应 起始位置，predicate ， 第一维度/头（取字o元组）\n",
        "                object_labels[o[1], o[2], 1] = 1 # 同上\n",
        "            # 构建batch\n",
        "            batch_input_ids.append(input_ids)  # 将上述值加入batch\n",
        "            batch_attention_mask.append(attention_mask)\n",
        "            batch_subject_labels.append(subject_labels)\n",
        "            batch_subject_ids.append(subject_ids)\n",
        "            batch_object_labels.append(object_labels)\n",
        "            if len(batch_subject_labels) == batch_size or i == len(data) - 1: # 没有补偿\n",
        "                batch_input_ids = sequence_padding(batch_input_ids)\n",
        "                batch_attention_mask = sequence_padding(batch_attention_mask)\n",
        "                batch_subject_labels = sequence_padding(batch_subject_labels)\n",
        "                batch_subject_ids = np.array(batch_subject_ids)\n",
        "                batch_object_labels = sequence_padding(batch_object_labels)\n",
        "                yield [\n",
        "                          torch.from_numpy(batch_input_ids).long(), torch.from_numpy(batch_attention_mask).long(),\n",
        "                          torch.from_numpy(batch_subject_labels), torch.from_numpy(batch_subject_ids),\n",
        "                          torch.from_numpy(batch_object_labels)\n",
        "                      ], None\n",
        "                batch_input_ids, batch_attention_mask = [], [] # 清空进入下个batch\n",
        "                batch_subject_labels, batch_subject_ids, batch_object_labels = [], [], []\n",
        " \n",
        " \n",
        "if os.path.exists('graph_model.bin'):  # 加载模型 保存档将graph model 加载过来\n",
        "    print('load model')\n",
        "    model = torch.load('graph_model.bin').to(device)\n",
        "    subject_model = model.encoder\n",
        "else:\n",
        "\n",
        "    #subject_model = SubjectModel.from_pretrained('facebook/bart-base') # 没有使用bert train\n",
        "    subject_model = SubjectModel.from_pretrained('bert-base-cased') # 没有使用bert train\n",
        "    subject_model.to(device)\n",
        " \n",
        "    model = ObjectModel(subject_model)\n",
        "    model.to(device)\n",
        " \n",
        "train_loader = data_generator(train_data, batch_size=8) # dataloader = 8\n",
        " \n",
        "optim = AdamW(model.parameters(), lr=5e-10) # 加速器 adamw 学习率 5e-5\n",
        "loss_func = torch.nn.BCELoss() # cross binary loss\n",
        " \n",
        "model.train()\n",
        "# print(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t4S13hrX8kIU",
        "outputId": "c6ef4d6f-c78d-4fec-d4d8-33c52351abe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************start train************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss:1.0569047927856445: : 2it [00:04,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss:0.9928063154220581: : 3it [00:08,  2.68s/it]\n",
            "0it [10:04, ?it/s]\n",
            "0it [01:54, ?it/s]\n",
            "\n",
            "1it [00:04,  4.94s/it]\u001b[A\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 1it [00:04,  4.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.381501692339554e-14 precision: 6.907985631389839e-15 recall: 9.999999999e-11\n",
            "2 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:08,  3.88s/it]\u001b[A\n",
            "train loss:5.001397609710693: : 2it [00:08,  3.88s/it]                    \u001b[A\n",
            "\n",
            "train loss:5.001397609710693: : 2it [00:08,  4.05s/it]\n",
            "\n",
            "\n",
            "1it [00:05,  5.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 4it [00:21,  7.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.1798017932987122e-14 precision: 5.899356970090226e-15 recall: 9.999999999e-11\n",
            "3 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:12,  6.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:4.118460655212402: : 2it [00:12,  6.13s/it]                    \u001b[A\u001b[A\n",
            "train loss:4.118460655212402: : 2it [00:12,  6.07s/it]\n",
            "\n",
            "1it [00:06,  6.17s/it]\u001b[A\n",
            "f1: 0.00011, precision: 0.00005, recall: 1.00000: : 1it [00:06,  6.17s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: {('The Big Fisherman', 'direct', 'Frank Borzage')}\n",
            "f1: 0.00010700337061687331 precision: 5.3504547891920534e-05 recall: 1.0\n",
            "4 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00011, precision: 0.00005, recall: 1.00000: : 2it [00:08,  3.94s/it]\u001b[A\n",
            "train loss:1.564520001411438: : 2it [00:08,  3.94s/it]                    \u001b[A\n",
            "\n",
            "train loss:1.564520001411438: : 2it [00:08,  4.29s/it]\n",
            "\n",
            "\n",
            "1it [00:05,  5.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 5it [00:41, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.2880788304244054e-14 precision: 6.4408089656060385e-15 recall: 9.999999999e-11\n",
            "5 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:08,  4.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:4.4280242919921875: : 2it [00:08,  4.08s/it]                   \u001b[A\u001b[A\n",
            "train loss:4.4280242919921875: : 2it [00:08,  4.23s/it]\n",
            "\n",
            "1it [00:03,  3.67s/it]\u001b[A\n",
            "train loss:0.9928063154220581: : 6it [00:49, 10.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.785395465095487e-14 precision: 8.927774305865469e-15 recall: 9.999999999e-11\n",
            "6 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:07,  3.78s/it]\u001b[A\n",
            "train loss:7.5003204345703125: : 2it [00:07,  3.78s/it]                   \u001b[A\n",
            "\n",
            "train loss:7.5003204345703125: : 2it [00:07,  3.77s/it]\n",
            "\n",
            "\n",
            "1it [00:05,  5.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 7it [00:58,  9.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.2239153050608748e-14 precision: 6.11995104039164e-15 recall: 9.999999999e-11\n",
            "7 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:12,  6.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:10.608686447143555: : 2it [00:12,  6.53s/it]                   \u001b[A\u001b[A\n",
            "train loss:10.608686447143555: : 2it [00:12,  6.40s/it]\n",
            "\n",
            "1it [00:05,  5.55s/it]\u001b[A\n",
            "train loss:0.9928063154220581: : 8it [01:11, 10.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: {('The Big Fisherman', 'direct', 'Frank Borzage')}\n",
            "f1: 0.00011041793188317663 precision: 5.5212014139796524e-05 recall: 1.0\n",
            "8 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00011, precision: 0.00006, recall: 1.00000: : 2it [00:10,  4.98s/it]\u001b[A\n",
            "train loss:14.664387702941895: : 2it [00:10,  4.98s/it]                   \u001b[A\n",
            "\n",
            "train loss:14.664387702941895: : 2it [00:10,  5.08s/it]\n",
            "\n",
            "\n",
            "1it [00:07,  7.28s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 9it [01:23, 11.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 9.370314842578624e-15 precision: 4.685376938574687e-15 recall: 9.999999999e-11\n",
            "9 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:10,  4.72s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:2.323152780532837: : 2it [00:10,  4.72s/it]                    \u001b[A\u001b[A\n",
            "train loss:2.323152780532837: : 2it [00:10,  5.12s/it]\n",
            "\n",
            "1it [00:06,  6.30s/it]\u001b[A\n",
            "train loss:0.9928063154220581: : 10it [01:32, 10.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.2293318581350884e-14 precision: 6.147037128104216e-15 recall: 9.999999999e-11\n",
            "10 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:09,  4.19s/it]\u001b[A\n",
            "train loss:4.240323543548584: : 2it [00:09,  4.19s/it]                    \u001b[A\n",
            "\n",
            "train loss:4.240323543548584: : 2it [00:09,  4.52s/it]\n",
            "\n",
            "\n",
            "1it [00:06,  6.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 11it [01:41, 10.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.0609516736512542e-14 precision: 5.305039787798381e-15 recall: 9.999999999e-11\n",
            "11 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:11,  5.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:4.064459323883057: : 2it [00:11,  5.78s/it]                    \u001b[A\u001b[A\n",
            "train loss:4.064459323883057: : 2it [00:11,  5.89s/it]\n",
            "\n",
            "1it [00:03,  3.99s/it]\u001b[A\n",
            "train loss:0.9928063154220581: : 12it [01:50,  9.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.5831552283701167e-14 precision: 7.916402786573718e-15 recall: 9.999999999e-11\n",
            "12 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:06,  3.24s/it]\u001b[A\n",
            "train loss:2.846971035003662: : 2it [00:06,  3.24s/it]                    \u001b[A\n",
            "\n",
            "train loss:2.846971035003662: : 2it [00:06,  3.36s/it]\n",
            "\n",
            "\n",
            "1it [00:05,  5.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 13it [01:58,  9.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.2868356710847859e-14 precision: 6.43459236857341e-15 recall: 9.999999999e-11\n",
            "13 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:11,  6.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:10.432960510253906: : 2it [00:11,  6.07s/it]                   \u001b[A\u001b[A\n",
            "train loss:10.432960510253906: : 2it [00:11,  5.92s/it]\n",
            "\n",
            "1it [00:07,  7.67s/it]\u001b[A\n",
            "train loss:0.9928063154220581: : 14it [02:13, 10.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 8.859357696566922e-15 precision: 4.429875077522795e-15 recall: 9.999999999e-11\n",
            "14 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:11,  5.23s/it]\u001b[A\n",
            "train loss:1.133895993232727: : 2it [00:11,  5.23s/it]                    \u001b[A\n",
            "\n",
            "train loss:1.133895993232727: : 2it [00:11,  5.60s/it]\n",
            "\n",
            "\n",
            "1it [00:08,  8.69s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 15it [02:25, 11.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 7.632713811395585e-15 precision: 3.816502557056699e-15 recall: 9.999999999e-11\n",
            "15 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:11,  5.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:3.0553245544433594: : 2it [00:11,  5.46s/it]                   \u001b[A\u001b[A\n",
            "train loss:3.0553245544433594: : 2it [00:11,  5.95s/it]\n",
            "\n",
            "1it [00:05,  5.22s/it]\u001b[A\n",
            "train loss:0.9928063154220581: : 16it [02:33, 10.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.292073131339217e-14 precision: 6.460783046905244e-15 recall: 9.999999999e-11\n",
            "16 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:08,  4.00s/it]\u001b[A\n",
            "train loss:1.2628878355026245: : 2it [00:08,  4.00s/it]                   \u001b[A\n",
            "\n",
            "train loss:1.2628878355026245: : 2it [00:08,  4.19s/it]\n",
            "\n",
            "\n",
            "1it [00:05,  5.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 17it [02:42, 10.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: {('The Big Fisherman', 'direct', 'Frank Borzage')}\n",
            "f1: 0.00010318852544628933 precision: 5.1596924828439964e-05 recall: 1.0\n",
            "17 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00010, precision: 0.00005, recall: 1.00000: : 2it [00:09,  4.65s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:8.718551635742188: : 2it [00:09,  4.65s/it]                    \u001b[A\u001b[A\n",
            "train loss:8.718551635742188: : 2it [00:09,  4.85s/it]\n",
            "\n",
            "1it [00:06,  6.09s/it]\u001b[A\n",
            "train loss:0.9928063154220581: : 18it [02:52,  9.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.1047892614483668e-14 precision: 5.524251463926608e-15 recall: 9.999999999e-11\n",
            "18 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:09,  4.27s/it]\u001b[A\n",
            "train loss:1.380097508430481: : 2it [00:09,  4.27s/it]                    \u001b[A\n",
            "\n",
            "train loss:1.380097508430481: : 2it [00:09,  4.56s/it]\n",
            "\n",
            "\n",
            "1it [00:04,  4.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:0.9928063154220581: : 19it [02:59,  9.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R and T: set()\n",
            "f1: 1.510231820584437e-14 precision: 7.551729346020182e-15 recall: 9.999999999e-11\n",
            "19 step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "f1: 0.00000, precision: 0.00000, recall: 0.00000: : 2it [00:07,  3.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss:2.721737861633301: : 2it [00:07,  3.62s/it]                    \u001b[A\u001b[A\n",
            "train loss:2.721737861633301: : 2it [00:07,  3.70s/it]\n",
            "train loss:0.9928063154220581: : 19it [03:04,  9.72s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f14c9907396f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'************start train************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-f14c9907396f>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m                             _, object_preds = model(en.input_ids.to(device), # 将input分词的结果添加进去\n\u001b[1;32m    102\u001b[0m                                                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# s的下标添加进去\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                                     en.attention_mask.to(device)) # 将mask添加进去\n\u001b[0m\u001b[1;32m    104\u001b[0m                             \u001b[0mobject_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 转换成numpy数组\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                             \u001b[0;31m# print(\"validate: object_preds\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-a7d04b708029>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, subject_position, attention_mask)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubject_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# print(\"ObjectModel\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# print(output, subject_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msubject_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_subject_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-a7d04b708029>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msubject_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m         )\n\u001b[1;32m   1026\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m                 )\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         )\n\u001b[1;32m    496\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         )\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class SPO(tuple):\n",
        "    def __init__(self, spo):\n",
        "        self.spox = (\n",
        "            spo[0],\n",
        "            spo[1],\n",
        "            spo[2],\n",
        "        )\n",
        " \n",
        "    def __hash__(self):\n",
        "        return self.spox.__hash__()\n",
        " \n",
        "    def __eq__(self, spo):\n",
        "        return self.spox == spo.spox\n",
        " \n",
        " \n",
        "def train_func():\n",
        "    train_loss = 0\n",
        "    pbar = tqdm(train_loader) # 开启进度条并遍历 train_loader\n",
        "    for step, batch in enumerate(pbar): # 遍历每个step 和 batch\n",
        "        print(step,'step')\n",
        "        optim.zero_grad()  # 将每个梯度清零\n",
        "        batch = batch[0] # 将batch 数据取出来第一个维度\n",
        "        \n",
        "        input_ids = batch[0].to(device) # text对应bert词典的下标\n",
        "        # print(input_ids,'input_ids') 1\n",
        "        attention_mask = batch[1].to(device) # mask\n",
        "        # print(attention_mask,'attention_mask') 2\n",
        "        subject_labels = batch[2].to(device) # subject对应bert词典的下标\n",
        "        subject_ids = batch[3].to(device) # subject 在句子中id\n",
        "        object_labels = batch[4].to(device) # object对应bert词典的下标\n",
        " \n",
        "        subject_out, object_out = model(input_ids, subject_ids.float(), attention_mask) # 拿到subject和object输出\n",
        "        subject_out = subject_out * attention_mask.unsqueeze(-1) # 将输入中补长的位置变成 0 / input当中的padding\n",
        "        object_out = object_out * attention_mask.unsqueeze(-1).unsqueeze(-1)#  同上\n",
        "\n",
        "        # print(\"subject_loss:\", subject_out.shape, subject_out, subject_labels.shape, subject_labels) 3\n",
        "        subject_loss = loss_func(subject_out, subject_labels.float()) # 识别subject的损失函数\n",
        "        # print(\"object_loss:\", object_out.shape, object_out, object_labels.shape, object_labels) 4\n",
        "        object_loss = loss_func(object_out, object_labels.float()) #  识别object的损失函数\n",
        " \n",
        "        # subject_loss = torch.mean(subject_loss, dim=2)\n",
        "        # subject_loss = torch.sum(subject_loss * attention_mask) / torch.sum(attention_mask)\n",
        " \n",
        "        loss = subject_loss + object_loss # 将loss进行相加 根据实际情况添加超参数\n",
        " \n",
        "        train_loss += loss.item() # 累加到train loss\n",
        "        loss.backward() # 反向传播\n",
        "        optim.step() # 更新参数\n",
        " \n",
        "        pbar.update()\n",
        "        pbar.set_description(f'train loss:{loss.item()}')  # 显示更新参数\n",
        " \n",
        "        if step % 1000 == 0:  # 每跑1000个step 保存模型\n",
        "            torch.save(model, 'graph_model.bin')\n",
        " \n",
        "        if step % 1 == 0 and step != 0:  # 每跑100步在验证集当中检验效果\n",
        "            with torch.no_grad():\n",
        "                # texts = ['The film stars William Boyd, Russell Hayden, Andy Clyde, Eleanor Stewart, Morris Ankrum and William Haade.',\n",
        "                #          'Texas Rangers Ride Again is a 1940 American Western film directed by James P. Hogan, written by William R. Lipman and Horace McCoy, and starring Ellen Drew, John Howard, Akim Tamiroff, May Robson, Broderick Crawford, Charley Grapewin, and John Miljan.']\n",
        "                X, Y, Z = 1e-10, 1e-10, 1e-10\n",
        "                pbar = tqdm()\n",
        "                spo = []\n",
        "                for data in valid_data[0:1]: # 遍历验证集\n",
        "                # for text in texts:\n",
        "                    text = data['text'] # 取出text\n",
        "                    spo_ori = data['spo_list'] # 去除三元组\n",
        "                    en = tokenizer(text=text, return_tensors='pt') # 将text分词\n",
        "                    _, subject_preds = subject_model(en.input_ids.to(device), en.attention_mask.to(device)) # 检验阶段需要预测subject的下标\n",
        "                    subject_preds = subject_preds.cpu().data.numpy() # 将下标转换成numpy数组\n",
        "                    # print(\"validate: subject_preds\")\n",
        "                    # print(subject_preds)\n",
        "                    start = np.where(subject_preds[0, :, 0] > 0.5)[0] # 阈值，大于0.5判断为start\n",
        "                    end = np.where(subject_preds[0, :, 1] > 0.4)[0] # 阈值 大于0.4判断为end # 阈值自己设定\n",
        "                    # print(start, end)\n",
        "                    subjects = []\n",
        "                    for i in start: # 遍历start 用来应对多个start的情况\n",
        "                        i_end = [end[j] for j in range(len(end)) if end[j] >= i and end[j] <= i+6] # 只取大于start的end 否则会出现逻辑错误\n",
        "                        # print(\"i and j:\")\n",
        "                        # print(i_end)\n",
        "                        if len(i_end)>0: # 如果 end 大于0将 start end 成对加入subject\n",
        "                            for j in i_end:\n",
        "                              subjects.append((i, j))\n",
        "                    # print(subjects)\n",
        "                    if subjects:\n",
        "                        for s in subjects: # 遍历每个s\n",
        "                            index = en.input_ids.cpu().data.numpy().squeeze(0)[s[0]:s[1] + 1] # 根据输入的下标\n",
        "                            # print(\"subject index:\")\n",
        "                            # print(index)\n",
        "                            subject = '' # 将bert的vcab里的汉字映射出来\n",
        "                            for i in index:\n",
        "                              v = vocab[i]\n",
        "                              if i == 102:\n",
        "                                continue\n",
        "                              if v.startswith('##'):\n",
        "                                v = v.split('#')[-1]\n",
        "                                subject += v\n",
        "                              else:\n",
        "                                subject += ' ' + v\n",
        "                            subject = subject.strip()\n",
        "                            # print(subject)\n",
        "                            _, object_preds = model(en.input_ids.to(device), # 将input分词的结果添加进去\n",
        "                                                    torch.from_numpy(np.array([s])).float().to(device), # s的下标添加进去\n",
        "                                                    en.attention_mask.to(device)) # 将mask添加进去\n",
        "                            object_preds = object_preds.cpu().data.numpy() # 转换成numpy数组\n",
        "                            # print(\"validate: object_preds\")\n",
        "                            # print(\"shape of object_preds________________________________________________\")\n",
        "                            # print(object_preds.shape)\n",
        "                            for object_pred in object_preds:  # 遍历所有的object\n",
        "                                # print(object_pred.shape)\n",
        "                                start = np.where(object_pred[:, :, 0] > 0.4) # object的阈值大于0.2取start\n",
        "                                end = np.where(object_pred[:, :, 1] > 0.2) # 同上\n",
        "                                for _start, predicate1 in zip(*start): # 星号zip代表把两个值解开 两行对应的元组 # 遍历start取 s 和 p\n",
        "                                    for _end, predicate2 in zip(*end): # 遍历end 取 e 和 p\n",
        "                                        if _start <= _end and _end <= _start+6 and predicate1 == predicate2: # 判断是否复合逻辑 spo\n",
        "                                            index = en.input_ids.cpu().data.numpy().squeeze(0)[_start:_end + 1] # 从输入中找到对应下标\n",
        "                                            # the_object = ' '.join([vocab[i] for i in index]) # 从bert词典中映射成中文\n",
        "                                            the_object = '' # 将bert的vcab里的汉字映射出来\n",
        "                                            for i in index:\n",
        "                                              v = vocab[i]\n",
        "                                              if i == 102:\n",
        "                                                continue\n",
        "                                              if v.startswith('##'):\n",
        "                                                v = v.split('#')[-1]\n",
        "                                                the_object += v\n",
        "                                              else:\n",
        "                                                the_object += ' ' + v\n",
        "                                            the_object = the_object.strip()\n",
        "                                            predicate = id2predicate[str(predicate1)] # 找predicate下标返回predicate\n",
        "                                            # print(object, '\\t', predicate)\n",
        "                                            spo.append([subject, predicate, the_object])  # 三元组放到数组当中\n",
        "                    # 预测结果\n",
        "                    # print(\"Calculate the score:\")\n",
        "                    R = set([SPO(_spo) for _spo in spo]) # 预测去重\n",
        "                    # print('R:', R)\n",
        "                    # 真实结果\n",
        "                    T = set([SPO(_spo) for _spo in spo_ori]) # 真是去重\n",
        "                    # print('T:', T)\n",
        "                    print('R and T:', R.intersection(T))\n",
        "                    # R = set(spo_ori)\n",
        "                    # T = set(spo)\n",
        "                    # 交集\n",
        "                    X += len(R.intersection(T)) #& T R & T 交集长度\n",
        "                    Y += len(R)  # R 长度 预测结果个数\n",
        "                    Z += len(T)#=1 # T 长度 真实结果个数\n",
        "                    f1, precision, recall = 2 * X / (Y + Z), X / Y, X / Z # f1 精准度 召回率\n",
        "                    pbar.update()  # 把代码更新到pbar\n",
        "                    pbar.set_description(\n",
        "                        'f1: %.5f, precision: %.5f, recall: %.5f' % (f1, precision, recall)\n",
        "                    )\n",
        "                # pbar.close()\n",
        "                print('f1:', f1, 'precision:', precision, 'recall:', recall)\n",
        " \n",
        " \n",
        "for epoch in range(20):\n",
        "    print('************start train************')\n",
        "    train_func()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e8711a38d3d4ae2b35ec613fe972e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf34fa824ce64d5999133343ba62ea66",
              "IPY_MODEL_27d477826ea140719eb8ea49145df51c",
              "IPY_MODEL_6dcfbb9bd779494cb56e1346d81d5615"
            ],
            "layout": "IPY_MODEL_f0fb12094dfe4423a7d12d63851c75cc"
          }
        },
        "cf34fa824ce64d5999133343ba62ea66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_effd34550bfa4877b86d2d5b0ce34cfd",
            "placeholder": "​",
            "style": "IPY_MODEL_43130e7494794f7aac971b552d5f0fb9",
            "value": "Downloading: 100%"
          }
        },
        "27d477826ea140719eb8ea49145df51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab64068135742489aba372ed397c46f",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91f7e048b2084c2e9479f7319908ba8e",
            "value": 29
          }
        },
        "6dcfbb9bd779494cb56e1346d81d5615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68293bef8a8548c9bb60320c6c1bab7a",
            "placeholder": "​",
            "style": "IPY_MODEL_e71e3e887e834d5a8a26c8d823233c02",
            "value": " 29.0/29.0 [00:00&lt;00:00, 979B/s]"
          }
        },
        "f0fb12094dfe4423a7d12d63851c75cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "effd34550bfa4877b86d2d5b0ce34cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43130e7494794f7aac971b552d5f0fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aab64068135742489aba372ed397c46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f7e048b2084c2e9479f7319908ba8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68293bef8a8548c9bb60320c6c1bab7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e71e3e887e834d5a8a26c8d823233c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6586bae032a94d00a8f48a4cf3ce4eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae6314599b00412ab284259ba55c4b05",
              "IPY_MODEL_cd86d37125604c1eb38fe64e29736584",
              "IPY_MODEL_3bacf3b5dbf8422d868276907a9139ad"
            ],
            "layout": "IPY_MODEL_33fbe4b2453e4c9aaa0dfb4feaf5fed4"
          }
        },
        "ae6314599b00412ab284259ba55c4b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef90620cf284ae4a8e4f4d1f6a69ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_1e23d8f7b1ae4aae9907162ca85d0cbb",
            "value": "Downloading: 100%"
          }
        },
        "cd86d37125604c1eb38fe64e29736584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2233387d6ec84410b0bec8c19d8d66ab",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5a872f02c0e4d7bbe3bd9ac718687b0",
            "value": 570
          }
        },
        "3bacf3b5dbf8422d868276907a9139ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8f387414dc14e94ad1a89ba50543403",
            "placeholder": "​",
            "style": "IPY_MODEL_d8b60da1468844ee8d9be8a4aa18cdf7",
            "value": " 570/570 [00:00&lt;00:00, 4.63kB/s]"
          }
        },
        "33fbe4b2453e4c9aaa0dfb4feaf5fed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef90620cf284ae4a8e4f4d1f6a69ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e23d8f7b1ae4aae9907162ca85d0cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2233387d6ec84410b0bec8c19d8d66ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a872f02c0e4d7bbe3bd9ac718687b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8f387414dc14e94ad1a89ba50543403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b60da1468844ee8d9be8a4aa18cdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2df4c8772ec2431a8554cd9583ff144a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cf1008992ba4350a93c0995a97cdb1f",
              "IPY_MODEL_568a567f1d5e4e5d8561ea43dbcd1f02",
              "IPY_MODEL_8d8865ad3e904e64afbbc2edf2c831d6"
            ],
            "layout": "IPY_MODEL_f3acc7f024264402abc06f977e641f88"
          }
        },
        "1cf1008992ba4350a93c0995a97cdb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_791ef16d84e249429ae4339efbe4c302",
            "placeholder": "​",
            "style": "IPY_MODEL_90b13cafd43845b3af9d7e49f82b3786",
            "value": "Downloading: 100%"
          }
        },
        "568a567f1d5e4e5d8561ea43dbcd1f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5ea0f2379274045be5b6a8e4a7b9c12",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bb5e411475248278de06318149834cb",
            "value": 435797
          }
        },
        "8d8865ad3e904e64afbbc2edf2c831d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cb2aa2043314b8a80b987ce3018a57f",
            "placeholder": "​",
            "style": "IPY_MODEL_5d8c20a381d84d33a642dc924e640888",
            "value": " 436k/436k [00:01&lt;00:00, 415kB/s]"
          }
        },
        "f3acc7f024264402abc06f977e641f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791ef16d84e249429ae4339efbe4c302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b13cafd43845b3af9d7e49f82b3786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5ea0f2379274045be5b6a8e4a7b9c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb5e411475248278de06318149834cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cb2aa2043314b8a80b987ce3018a57f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d8c20a381d84d33a642dc924e640888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}