{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTiUsjV5-Nf0",
        "outputId": "eb67c29d-3183-45a8-f37b-f107147baf96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 代码复现\n",
        "https://github.com/terrifyzhao/spo_extract"
      ],
      "metadata": {
        "id": "suM-xucptE0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## train 代码\n",
        " \n",
        "import json\n",
        "from tqdm import tqdm   # 进度条\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, AdamW\n",
        "import torch\n",
        "# from model import ObjectModel, SubjectModel\n",
        " \n",
        "GPU_NUM = 0\n",
        " \n",
        "#device = torch.device(f'cuda:{GPU_NUM}') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device = torch.device('cpu')\n",
        " \n",
        "vocab = {}\n",
        "with open('vocab.txt')as file:  # 使用with open 的方法读取词典\n",
        "    for l in file.readlines():\n",
        "        vocab[len(vocab)] = l.strip() # 根据key读取词典\n",
        " \n",
        " \n",
        "def load_data(filename):  # 中文解码加载数据\n",
        "    \"\"\"加载数据\n",
        "    单条格式：{'text': text, 'spo_list': [[s, p, o]]}\n",
        "    \"\"\"\n",
        "    with open(filename) as f:\n",
        "        json_list = json.load(f)\n",
        "    return json_list\n",
        " \n",
        " \n",
        "# 加载数据集\n",
        "train_data = load_data('train_fulltext.json')\n",
        "valid_data = load_data('dev_fulltext.json')"
      ],
      "metadata": {
        "id": "vTtWKjhJtD9e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0],len(train_data),valid_data[0],len(valid_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVipT19ZpUIa",
        "outputId": "dcb099fb-2160-4376-b150-3ca25893146c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'text': 'The Birth of a Nation, originally called The Clansman, is a 1915 American silent epic drama film directed by D. W. Griffith and starring Lillian Gish. The screenplay is adapted from Thomas Dixon Jr.\\'s 1905 novel and play \"\". Griffith co-wrote the screenplay with Frank E. Woods and produced the film with Harry Aitken.\\n\"The Birth of a Nation\" is a landmark of film history, lauded for its technical virtuosity. It was the first American 12-reel film ever made and, at three hours, also the longest up to that point. Its plot, part fiction and part history, chronicles the assassination of Abraham Lincoln by John Wilkes Booth and the relationship of two families in the Civil War and Reconstruction eras over the course of several years—the pro-Union (Northern) Stonemans and the pro-Confederacy (Southern) Camerons. It was originally shown in two parts separated by an intermission, and it was the first American-made film to have a musical score for an orchestra. It pioneered closeups and fadeouts, and it includes a care',\n",
              "  'spo_list': [['The Birth of a Nation', 'direct', 'D. W. Griffith']]},\n",
              " 500,\n",
              " {'text': 'Heart of Arizona is a 1938 American Western film directed by Lesley Selander and written by Norman Houston. The film stars William Boyd, George \"Gabby\" Hayes, Russell Hayden, John Elliott, Billy King, Natalie Moorhead and Dorothy Short. The film was released on April 22, 1938, by Paramount Pictures.\\nPlot.\\nBelle (Natalie Moorhead) is being released after serving a five-year prison sentence for standing by her outlaw husband, Sam. The sheriff (John Beach) wants to drop her off in a Nogales dancehall, but Hoppy (William Boyd) forces him to let her go back to her ranch.',\n",
              "  'spo_list': [['Heart of Arizona', 'act', 'Russell Hayden']]},\n",
              " 281)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")   # 调用分词器\n",
        " \n",
        "with open('schemas.json') as f: # 读取predicate\n",
        "    json_list = json.load(f)\n",
        "    id2predicate = json_list[0]\n",
        "    predicate2id = json_list[1]"
      ],
      "metadata": {
        "id": "RRkjL5PQtRAz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2predicate,predicate2id,len(id2predicate),len(predicate2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht5B7GwspjZ_",
        "outputId": "ad3b844d-8db3-4f71-cdcd-0c1930203d8e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'0': 'unknown', '1': 'direct', '2': 'act', '3': 'star'},\n",
              " {'unknown': 0, 'direct': 1, 'act': 2, 'star': 3},\n",
              " 4,\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertPreTrainedModel\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class SubjectModel(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.dense = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        subject_out = self.dense(output[0])\n",
        "        subject_out = torch.sigmoid(subject_out)\n",
        "\n",
        "        return output[0], subject_out\n",
        "\n",
        "\n",
        "class ObjectModel(nn.Module):\n",
        "    def __init__(self, subject_model):\n",
        "        super().__init__()\n",
        "        self.encoder = subject_model\n",
        "        self.dense_subject_position = nn.Linear(2, 768)\n",
        "        self.dense_object = nn.Linear(768, 4 * 2)\n",
        "\n",
        "    def forward(self,input_ids,subject_position,attention_mask=None):\n",
        "        output, subject_out = self.encoder(input_ids, attention_mask)\n",
        "\n",
        "        subject_position = self.dense_subject_position(subject_position).unsqueeze(1)\n",
        "        object_out = output + subject_position\n",
        "        # [bs, 768] -> [bs, 98]\n",
        "        object_out = self.dense_object(object_out)\n",
        "        # [bs, 98] -> [bs, 4, 2]\n",
        "        object_out = torch.reshape(object_out, (object_out.shape[0], object_out.shape[1], 4, 2))\n",
        "        object_out = torch.sigmoid(object_out)\n",
        "        object_out = torch.pow(object_out, 4)\n",
        "        return subject_out, object_out"
      ],
      "metadata": {
        "id": "9NoQ8aUFKMRO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(pattern, sequence):\n",
        "    \"\"\"从sequence中寻找子串pattern\n",
        "    如果找到，返回第一个下标；否则返回-1。\n",
        "    \"\"\"\n",
        "    n = len(pattern)\n",
        "    for i in range(len(sequence)):\n",
        "        if sequence[i:i + n] == pattern:\n",
        "            return i\n",
        "    return -1\n",
        " \n",
        " \n",
        "def sequence_padding(inputs, length=None, padding=0, mode='post'):\n",
        "    \"\"\"Numpy函数，将序列padding到同一长度\n",
        "    \"\"\"\n",
        "    if length is None:\n",
        "        length = max([len(x) for x in inputs])\n",
        " \n",
        "    pad_width = [(0, 0) for _ in np.shape(inputs[0])]\n",
        "    outputs = []\n",
        "    for x in inputs:\n",
        "        x = x[:length]\n",
        "        if mode == 'post':\n",
        "            pad_width[0] = (0, length - len(x))\n",
        "        elif mode == 'pre':\n",
        "            pad_width[0] = (length - len(x), 0)\n",
        "        else:\n",
        "            raise ValueError('\"mode\" argument must be \"post\" or \"pre\".')\n",
        "        x = np.pad(x, pad_width, 'constant', constant_values=padding)\n",
        "        outputs.append(x)\n",
        " \n",
        "    return np.array(outputs)"
      ],
      "metadata": {
        "id": "T6-7gMhIe819"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "l_HCxxJN9LBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6639fee4-b3ae-44a9-def0-b0e64aa06330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing SubjectModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing SubjectModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SubjectModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of SubjectModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['dense.weight', 'dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectModel(\n",
              "  (encoder): SubjectModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dense): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              "  (dense_subject_position): Linear(in_features=2, out_features=768, bias=True)\n",
              "  (dense_object): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "def data_generator(data, batch_size=3):  #  数据迭代器/数据生成器\n",
        " \n",
        "    batch_input_ids, batch_attention_mask = [], [] #  输出给模型（object）的变量，通过调用bert分词器得到\n",
        "    batch_subject_labels, batch_subject_ids, batch_object_labels = [], [], []\n",
        "    texts = []\n",
        "    for i, d in enumerate(data): #  数据来自dataloader i = 数据索引 d = text\n",
        "        text = d['text'] # 从train 中取出text\n",
        "        texts.append(text)   # text 贴入元组\n",
        "        encoding = tokenizer(text=text) # 使用bert 分词\n",
        "        input_ids, attention_mask = encoding.input_ids, encoding.attention_mask  # 分词后对应“bert词典下标”和mask\n",
        "        # 整理三元组 {s: [(o, p)]}\n",
        "        spoes = {}\n",
        "        for s, p, o in d['spo_list']: # 遍历三元组\n",
        "            # [cls] XXX [sep]\n",
        "            s_encoding = tokenizer(text=s).input_ids[1:-1]  # 将s，o编码成对应的下标\n",
        "            o_encoding = tokenizer(text=o).input_ids[1:-1]  # [1:-1] 去除cls sep\n",
        " \n",
        "            s_idx = search(s_encoding, input_ids) # 从text的input_ids 寻找s的下标\n",
        "            o_idx = search(o_encoding, input_ids) # 从text的input_ids 寻找o的下标\n",
        " \n",
        "            p = predicate2id[p]  # 的到predicate的下标\n",
        " \n",
        "            if s_idx != -1 and o_idx != -1: # 做判断没有反应的返回-1\n",
        "                s = (s_idx, s_idx + len(s_encoding) - 1) # s保存subject的起始位置，起始位置加上长度 -1\n",
        "                o = (o_idx, o_idx + len(o_encoding) - 1, p)# 同上 s,o 是一个元组保存着起始位置和终止位置的下标 以及 p\n",
        "                if s not in spoes:\n",
        "                    spoes[s] = []\n",
        "                spoes[s].append(o) # 将 下标加入 spoes 字典当中去\n",
        "        if spoes:\n",
        "            # subject标签\n",
        "            subject_labels = np.zeros((len(input_ids), 2)) # 生成一个input长度的二维向量/ s头s尾\n",
        "            for s in spoes:\n",
        "                # 注意要+1，因为有cls符号\n",
        "                subject_labels[s[0], 0] = 1 # 第一行 = ‘0’ 的起始 = s[0] 等于1\n",
        "                subject_labels[s[1], 1] = 1  # 第二行 = ‘1’ 的终止 =s[1] 等于1\n",
        "            # 一个s对应多个o时，随机选一个subject\n",
        "            start, end = np.array(list(spoes.keys())).T\n",
        "            start = np.random.choice(start)\n",
        "            end = np.random.choice(end[end >= start])\n",
        "            subject_ids = (start, end)\n",
        "            # 对应的object标签\n",
        "            object_labels = np.zeros((len(input_ids), len(predicate2id), 2)) # 序列长度 x predicate长度 x 2\n",
        "            for o in spoes.get(subject_ids, []): # 通过subject 拿出对应的 o\n",
        "                object_labels[o[0], o[2], 0] = 1 # 对应 起始位置，predicate ， 第一维度/头（取字o元组）\n",
        "                object_labels[o[1], o[2], 1] = 1 # 同上\n",
        "            # 构建batch\n",
        "            batch_input_ids.append(input_ids)  # 将上述值加入batch\n",
        "            batch_attention_mask.append(attention_mask)\n",
        "            batch_subject_labels.append(subject_labels)\n",
        "            batch_subject_ids.append(subject_ids)\n",
        "            batch_object_labels.append(object_labels)\n",
        "            if len(batch_subject_labels) == batch_size or i == len(data) - 1: # 没有补偿\n",
        "                batch_input_ids = sequence_padding(batch_input_ids)\n",
        "                batch_attention_mask = sequence_padding(batch_attention_mask)\n",
        "                batch_subject_labels = sequence_padding(batch_subject_labels)\n",
        "                batch_subject_ids = np.array(batch_subject_ids)\n",
        "                batch_object_labels = sequence_padding(batch_object_labels)\n",
        "                yield [\n",
        "                          torch.from_numpy(batch_input_ids).long(), torch.from_numpy(batch_attention_mask).long(),\n",
        "                          torch.from_numpy(batch_subject_labels), torch.from_numpy(batch_subject_ids),\n",
        "                          torch.from_numpy(batch_object_labels)\n",
        "                      ], None\n",
        "                batch_input_ids, batch_attention_mask = [], [] # 清空进入下个batch\n",
        "                batch_subject_labels, batch_subject_ids, batch_object_labels = [], [], []\n",
        " \n",
        " \n",
        "if os.path.exists('graph_model.bin'):  # 加载模型 保存档将graph model 加载过来\n",
        "    print('load model')\n",
        "    model = torch.load('graph_model.bin').to(device)\n",
        "    subject_model = model.encoder\n",
        "else:\n",
        "\n",
        "    #subject_model = SubjectModel.from_pretrained('facebook/bart-base') # 没有使用bert train\n",
        "    subject_model = SubjectModel.from_pretrained('bert-base-cased') # 没有使用bert train\n",
        "    subject_model.to(device)\n",
        " \n",
        "    model = ObjectModel(subject_model)\n",
        "    model.to(device)\n",
        " \n",
        "train_loader = data_generator(train_data, batch_size=8) # dataloader = 8\n",
        " \n",
        "optim = AdamW(model.parameters(), lr=5e-6) # 加速器 adamw 学习率 5e-5\n",
        "loss_func = torch.nn.BCELoss() # cross binary loss\n",
        " \n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SPO(tuple):\n",
        "    def __init__(self, spo):\n",
        "        self.spox = (\n",
        "            spo[0],\n",
        "            spo[1],\n",
        "            spo[2],\n",
        "        )\n",
        " \n",
        "    def __hash__(self):\n",
        "        return self.spox.__hash__()\n",
        " \n",
        "    def __eq__(self, spo):\n",
        "        return self.spox == spo.spox\n",
        " \n",
        " \n",
        "def train_func():\n",
        "    train_loss = 0\n",
        "    pbar = tqdm(train_loader) # 开启进度条并遍历 train_loader\n",
        "    for step, batch in enumerate(pbar): # 遍历每个step 和 batch\n",
        "        optim.zero_grad()  # 将每个梯度清零\n",
        "        batch = batch[0] # 将batch 数据取出来第一个维度\n",
        "        input_ids = batch[0].to(device) # text对应bert词典的下标\n",
        "        attention_mask = batch[1].to(device) # mask\n",
        "        subject_labels = batch[2].to(device) # subject对应bert词典的下标\n",
        "        subject_ids = batch[3].to(device) # subject 在句子中id\n",
        "        object_labels = batch[4].to(device) # object对应bert词典的下标\n",
        " \n",
        "        subject_out, object_out = model(input_ids, subject_ids.float(), attention_mask) # 拿到subject和object输出\n",
        "        subject_out = subject_out * attention_mask.unsqueeze(-1) # 将输入中补长的位置变成 0 / input当中的padding\n",
        "        object_out = object_out * attention_mask.unsqueeze(-1).unsqueeze(-1)#  同上\n",
        " \n",
        "        subject_loss = loss_func(subject_out, subject_labels.float()) # 识别subject的损失函数\n",
        "        object_loss = loss_func(object_out, object_labels.float()) #  识别object的损失函数\n",
        " \n",
        "        # subject_loss = torch.mean(subject_loss, dim=2)\n",
        "        # subject_loss = torch.sum(subject_loss * attention_mask) / torch.sum(attention_mask)\n",
        " \n",
        "        loss = subject_loss + object_loss # 将loss进行相加 根据实际情况添加超参数\n",
        " \n",
        "        train_loss += loss.item() # 累加到train loss\n",
        "        loss.backward() # 反向传播\n",
        "        optim.step() # 更新参数\n",
        " \n",
        "        pbar.update()\n",
        "        pbar.set_description(f'train loss:{loss.item()}')  # 显示更新参数\n",
        " \n",
        "        if step % 1000 == 0:  # 每跑1000个step 保存模型\n",
        "            torch.save(model, 'graph_model.bin')\n",
        " \n",
        "        if step % 5 == 0 and step != 0:  # 每跑100步在验证集当中检验效果\n",
        "            with torch.no_grad():\n",
        "                # texts = ['The film stars William Boyd, Russell Hayden, Andy Clyde, Eleanor Stewart, Morris Ankrum and William Haade.',\n",
        "                #          'Texas Rangers Ride Again is a 1940 American Western film directed by James P. Hogan, written by William R. Lipman and Horace McCoy, and starring Ellen Drew, John Howard, Akim Tamiroff, May Robson, Broderick Crawford, Charley Grapewin, and John Miljan.']\n",
        "                X, Y, Z = 1e-10, 1e-10, 1e-10\n",
        "                pbar = tqdm()\n",
        "                spo = []\n",
        "                for data in valid_data[0:10]: # 遍历验证集\n",
        "                # for text in texts:\n",
        "                    text = data['text'] # 取出text\n",
        "                    spo_ori = data['spo_list'] # 去除三元组\n",
        "                    en = tokenizer(text=text, return_tensors='pt') # 将text分词\n",
        "                    _, subject_preds = subject_model(en.input_ids.to(device), en.attention_mask.to(device)) # 检验阶段需要预测subject的下标\n",
        "                    subject_preds = subject_preds.cpu().data.numpy() # 将下标转换成numpy数组\n",
        "                    start = np.where(subject_preds[0, :, 0] > 0.5)[0] # 阈值，大于0.5判断为start\n",
        "                    end = np.where(subject_preds[0, :, 1] > 0.4)[0] # 阈值 大于0.4判断为end # 阈值自己设定\n",
        "                    subjects = []\n",
        "                    for i in start: # 遍历start 用来应对多个start的情况\n",
        "                        j = end[end >= i] # 只取大于start的end 否则会出现逻辑错误\n",
        "                        if len(j) > 0: # 如果 end 大于0将 start end 成对加入subject\n",
        "                            j = j[0]\n",
        "                            subjects.append((i, j))\n",
        "                    # print(subjects)\n",
        "                    if subjects:\n",
        "                        for s in subjects: # 遍历每个s\n",
        "                            index = en.input_ids.cpu().data.numpy().squeeze(0)[s[0]:s[1] + 1] # 根据输入的下标\n",
        "                            subject = ''.join([vocab[i] for i in index]) # 将bert的vcab里的汉字映射出来\n",
        "                            # print(subject)\n",
        " \n",
        "                            _, object_preds = model(en.input_ids.to(device), # 将input分词的结果添加进去\n",
        "                                                    torch.from_numpy(np.array([s])).float().to(device), # s的下标添加进去\n",
        "                                                    en.attention_mask.to(device)) # 将mask添加进去\n",
        "                            object_preds = object_preds.cpu().data.numpy() # 转换成numpy数组\n",
        "                            for object_pred in object_preds:  # 遍历所有的object\n",
        "                                start = np.where(object_pred[:, :, 0] > 0.2) # object的阈值大于0.2取start\n",
        "                                end = np.where(object_pred[:, :, 1] > 0.2) # 同上\n",
        "                                for _start, predicate1 in zip(*start): # 星号zip代表把两个值解开 两行对应的元组 # 遍历start取 s 和 p\n",
        "                                    for _end, predicate2 in zip(*end): # 遍历end 取 e 和 p\n",
        "                                        if _start <= _end and predicate1 == predicate2: # 判断是否复合逻辑 spo\n",
        "                                            index = en.input_ids.cpu().data.numpy().squeeze(0)[_start:_end + 1] # 从输入中找到对应下标\n",
        "                                            object = ''.join([vocab[i] for i in index]) # 从bert词典中映射成中文\n",
        "                                            predicate = id2predicate[str(predicate1)] # 找predicate下标返回predicate\n",
        "                                            # print(object, '\\t', predicate)\n",
        "                                            spo.append([subject, predicate, object])  # 三元组放到数组当中\n",
        "                    # 预测结果\n",
        "                    R = set([SPO(_spo) for _spo in spo]) # 预测去重\n",
        "                    # print(R)\n",
        "                    # 真实结果\n",
        "                    T = set([SPO(_spo) for _spo in spo_ori]) # 真是去重\n",
        "                    # R = set(spo_ori)\n",
        "                    # T = set(spo)\n",
        "                    # 交集\n",
        "                    X += len(R ) #& T R & T 交集长度\n",
        "                    Y += len(R)  # R 长度\n",
        "                    Z+= len(T)#=1 # T 长度\n",
        "                    f1, precision, recall = 2 * X / (Y + Z), X / Y, X / Z # f1 精准度 召回率\n",
        "                    pbar.update()  # 把代码更新到pbar\n",
        "                    pbar.set_description(\n",
        "                        'f1: %.5f, precision: %.5f, recall: %.5f' % (f1, precision, recall)\n",
        "                    )\n",
        "                pbar.close()\n",
        "                print('f1:', f1, 'precision:', precision, 'recall:', recall)\n",
        " \n",
        " \n",
        "for epoch in range(20):\n",
        "    print('************start train************')\n",
        "    train_func()"
      ],
      "metadata": {
        "id": "t4S13hrX8kIU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "704cc438-c287-4dc2-dc0e-854200ec3a2f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************start train************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss:0.608623743057251: : 9it [01:58, 12.27s/it] \n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:02,  2.58s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 1it [00:02,  2.58s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 2it [00:06,  3.52s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 2it [00:06,  3.52s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 3it [00:12,  4.31s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 3it [00:12,  4.31s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 4it [00:19,  5.41s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 4it [00:19,  5.41s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 5it [00:31,  7.79s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 5it [00:31,  7.79s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 6it [00:44,  9.66s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 6it [00:44,  9.66s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 7it [00:53,  9.56s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 7it [00:53,  9.56s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 8it [01:00,  8.75s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 8it [01:00,  8.75s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 9it [01:16, 10.81s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 9it [01:16, 10.81s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 10it [01:25, 10.43s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 10it [01:25,  8.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1: 1.9999999999600002e-11 precision: 1.0 recall: 9.999999999900001e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss:0.608623743057251: : 10it [04:02, 38.94s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:01,  1.00s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 1it [00:01,  1.00s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 2it [00:01,  1.39it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 2it [00:01,  1.39it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 3it [00:02,  1.16it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 3it [00:02,  1.16it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 4it [00:04,  1.17s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 4it [00:04,  1.17s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 5it [00:05,  1.05s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 5it [00:05,  1.05s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 6it [00:06,  1.25s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 6it [00:06,  1.25s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 7it [00:08,  1.39s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 7it [00:08,  1.39s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 8it [00:09,  1.22s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 8it [00:09,  1.22s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 9it [00:10,  1.12s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 9it [00:10,  1.12s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 10it [00:11,  1.34s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 10it [00:11,  1.20s/it]\n",
            "train loss:0.608623743057251: : 11it [05:12, 46.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1: 1.9999999999600002e-11 precision: 1.0 recall: 9.999999999900001e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss:0.608623743057251: : 15it [06:29, 26.80s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:01,  1.01s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 1it [00:01,  1.01s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 2it [00:01,  1.36it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 2it [00:01,  1.36it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 3it [00:02,  1.57it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 3it [00:02,  1.57it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 4it [00:02,  1.39it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 4it [00:02,  1.39it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 5it [00:03,  1.31it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 5it [00:03,  1.31it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 6it [00:05,  1.06s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 6it [00:05,  1.06s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 7it [00:06,  1.01it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 7it [00:06,  1.01it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 8it [00:07,  1.20s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 8it [00:07,  1.20s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 9it [00:08,  1.08s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 9it [00:08,  1.08s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 10it [00:09,  1.03s/it]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 10it [00:09,  1.04it/s]\n",
            "train loss:0.608623743057251: : 16it [06:58, 27.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1: 1.9999999999600002e-11 precision: 1.0 recall: 9.999999999900001e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss:0.608623743057251: : 20it [08:18, 21.26s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:00,  1.87it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 1it [00:00,  1.87it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 2it [00:01,  1.85it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 2it [00:01,  1.85it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 3it [00:01,  1.85it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 3it [00:01,  1.85it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 4it [00:02,  1.50it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 4it [00:02,  1.50it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 5it [00:03,  1.37it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 5it [00:03,  1.37it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 6it [00:04,  1.31it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 6it [00:04,  1.31it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 7it [00:05,  1.26it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 7it [00:05,  1.26it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 8it [00:05,  1.23it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 8it [00:05,  1.23it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 9it [00:06,  1.22it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 9it [00:06,  1.22it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 10it [00:07,  1.17it/s]\u001b[A\n",
            "f1: 0.00000, precision: 1.00000, recall: 0.00000: : 10it [00:07,  1.31it/s]\n",
            "train loss:0.608623743057251: : 21it [08:46, 23.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1: 1.9999999999600002e-11 precision: 1.0 recall: 9.999999999900001e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss:0.608623743057251: : 24it [10:01, 25.08s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-74795bd7dab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'************start train************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-74795bd7dab3>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 累加到train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 反向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 更新参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}