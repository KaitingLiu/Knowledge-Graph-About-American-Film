{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Get the id list of all US films from wikipedia"
      ],
      "metadata": {
        "id": "g1T1qygZAsMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SPARQLWrapper\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLBpPhSBvFo6",
        "outputId": "27997245-bec9-4796-89b8-eeb3aee2fbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting rdflib>=6.1.1\n",
            "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (4.12.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 395 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=6.1.1->SPARQLWrapper) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=6.1.1->SPARQLWrapper) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate->rdflib>=6.1.1->SPARQLWrapper) (1.15.0)\n",
            "Installing collected packages: isodate, rdflib, SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-2.0.0 isodate-0.6.1 rdflib-6.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJYMl7Yuuych"
      },
      "outputs": [],
      "source": [
        "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
        "N_max = 60000\n",
        "index = 0\n",
        "nums=[]\n",
        "while index < N_max:\n",
        "  sql = \"\"\"\n",
        "  SELECT DISTINCT ?number\n",
        "  WHERE\n",
        "      {\n",
        "          ?film dbp:country ?country.\n",
        "          ?film dbo:wikiPageWikiLink dbc:American_films .\n",
        "          ?film dbo:wikiPageID ?number .\n",
        "          ?film rdfs:comment ?abstract .\n",
        "          ?film dbp:name ?name .\n",
        "        }\n",
        "  LIMIT 10000\n",
        "  OFFSET %d.\n",
        "  \"\"\" %(index)\n",
        "  sparql.setQuery(sql)\n",
        "  sparql.setReturnFormat(JSON)\n",
        "  results = sparql.query().convert()\n",
        "  dic=results['results']['bindings']\n",
        "  for idx in dic:\n",
        "    nums.append(idx['number']['value'])\n",
        "  index += 10000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(nums))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvkiMKwavX0J",
        "outputId": "2d67eb34-ce8a-4b15-bec3-1a3582a85700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52172"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter the json data by the id list"
      ],
      "metadata": {
        "id": "FSVwcmYPA6lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \n",
        "import json\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "json_data = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-BnhC52AmG7",
        "outputId": "22b0c132-2310-4f6c-8a3f-2859e08fd509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/dataset/AB.zip\" -d \"/content/drive/MyDrive/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhC4U19MF0gd",
        "outputId": "d8ff7110-6958-43ff-9e68-7c24b7e374e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/dataset/AB.zip\n",
            "   creating: /content/drive/MyDrive/dataset/AB/\n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/._AB  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_42  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_42  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/.DS_Store  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._.DS_Store  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_45  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_45  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_44  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_44  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_43  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_43  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_32  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_32  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_35  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_35  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_50  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_50  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_57  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_57  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_68  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_68  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_61  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_61  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_66  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_66  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_59  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_59  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_34  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_34  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_33  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_33  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_67  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_67  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_58  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_58  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_60  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_60  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_56  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_56  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_51  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_51  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_48  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_48  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_46  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_46  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_41  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_41  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_40  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_40  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_47  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_47  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_49  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_49  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_54  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_54  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_53  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_53  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_65  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_65  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_62  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_62  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_36  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_36  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_38  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_38  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_63  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_63  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_64  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_64  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_52  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_52  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_55  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_55  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_39  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_39  \n",
            "  inflating: /content/drive/MyDrive/dataset/AB/wiki_37  \n",
            "  inflating: /content/drive/MyDrive/dataset/__MACOSX/AB/._wiki_37  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_index = 32\n",
        "while file_index < 69:\n",
        "  file_path = '/content/drive/MyDrive/dataset/AB/wiki_' + str(file_index)\n",
        "  for line in open(file_path):\n",
        "    if json.loads(line)['id'] in nums:\n",
        "      json_data.append(json.loads(line))\n",
        "  file_index += 1"
      ],
      "metadata": {
        "id": "W2tcu1vwG1EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=open('file_4','wb')\n",
        "pickle.dump(json_data,df)\n",
        "df.close()"
      ],
      "metadata": {
        "id": "ah-roSZPBQcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=open('file_4','rb')\n",
        "data_tmp=pickle.load(df1)\n",
        "df1.close()\n",
        "len(data_tmp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V59ot2BOBSue",
        "outputId": "d3ce5b8b-2bb3-4b3f-928c-ccbfb61939c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14927"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP pipline"
      ],
      "metadata": {
        "id": "ORIaG_nBTfLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pickle\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "df1=open('file_4','rb')\n",
        "film_data=pickle.load(df1)\n",
        "df1.close()\n",
        "# len(film_data)"
      ],
      "metadata": {
        "id": "ESTaTOjwTeVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Processor:\n",
        "  def __init__(self, data):\n",
        "    self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "    self.films = []\n",
        "    self.data = data\n",
        "    self.matcher = Matcher(self.nlp.vocab)\n",
        "\n",
        "  def sentence_segmentation(self):\n",
        "    for film in self.data:\n",
        "      film_dict = {}\n",
        "      film_dict['title'] = film['title']\n",
        "      doc = self.nlp(film['text'])\n",
        "      triplets = []\n",
        "      for sent in doc.sents:\n",
        "        entities = []\n",
        "        for ent in sent.ents:\n",
        "          entities.append((ent.text,ent.label_))\n",
        "        # entities = entities.append(self.get_entities(sent, entities))\n",
        "        print(entities)\n",
        "        # triplets.append(triplet)\n",
        "      film_dict['triplets'] = triplets\n",
        "    self.films.append(film_dict)\n",
        "\n",
        "  def get_entities(self, doc, old_entities):\n",
        "    entities = []\n",
        "    ent =\"\"\n",
        "    prv_tok_dep =\"\" # dependency tag of previous token in the sentence\n",
        "    prv_tok_text =\"\" # previous token in the sentence\n",
        "    prefix =\"\"\n",
        "    modifier =\"\"\n",
        "    for tok in doc:\n",
        "      if tok.dep_ == \"punct\":\n",
        "        continue\n",
        "      if tok.dep_ == \"compound\":\n",
        "        prefix = tok.text\n",
        "        if prv_tok_dep == \"compound\":\n",
        "          prefix = prv_tok_text + \" \" + tok.text\n",
        "\n",
        "      if tok.dep_.endswith(\"mod\") == True:\n",
        "        modifier = tok.text\n",
        "        if prv_tok_dep ==\"compound\":\n",
        "          modifier = prv_tok_text + \" \" + tok.text\n",
        "\n",
        "      if tok.dep_.find(\"subj\") == True or tok.dep_.find(\"obj\") == True:\n",
        "        ent = modifier + \" \" + prefix + \" \" + tok.text\n",
        "        ent = ent.strip()\n",
        "        if not ent in old_entities:\n",
        "          entities.append(ent)\n",
        "\n",
        "      prefix =\"\"\n",
        "      modifier =\"\"\n",
        "      prv_tok_dep = tok.dep_\n",
        "      prv_tok_text = tok.text\n",
        "\n",
        "    return entities\n",
        "  \n",
        "  def get_relation(self, doc):\n",
        "    # Matcher class object\n",
        "    pattern = [{'DEP':'ROOT'},{'DEP':'prep','OP':\"?\"},{'DEP':'agent','OP':\"?\"},{'POS':'ADJ','OP':\"?\"}]\n",
        "    self.matcher.add(\"matching_1\", patterns=[pattern])\n",
        "    matches = self.matcher(doc)\n",
        "    k =len(matches) -1\n",
        "    span = doc[matches[k][1]:matches[k][2]]\n",
        "    return(span.text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ck4frb242ztr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "film_data = film_data[:1]\n",
        "p = Processor(film_data)\n",
        "p.sentence_segmentation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMOYqKSQUrJy",
        "outputId": "8a1139be-6642-407d-b6c5-2af445b39906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(\"Scatter My Ashes at Bergdorf's\", 'WORK_OF_ART'), ('US', 'GPE'), ('2013', 'DATE'), ('Matthew Miele', 'PERSON'), ('New York City', 'GPE'), ('Bergdorf Goodman', 'PERSON'), ('Fifth Avenue', 'FAC'), ('Grand Army Plaza', 'FAC')]\n",
            "[('1990', 'DATE'), ('Victoria Roberts', 'PERSON'), ('The New Yorker', 'WORK_OF_ART')]\n",
            "[]\n",
            "[('May 3, 2013', 'DATE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.films"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Fuaz_DVs2e",
        "outputId": "cfe8a0b2-9453-4b4a-86a8-ab90a7b30aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': \"Scatter My Ashes at Bergdorf's\", 'triplets': []}]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "str = 'Army of Darkness is a 1992 American comedy horror film directed, co-written and co-edited by Sam Raimi, co-produced by Robert Tapert and Bruce Campbell and co-written by Ivan Raimi.'\n",
        "doc = nlp(str)\n",
        "for tok in doc:\n",
        "  if tok.dep_.find(\"sub\") == True:\n",
        "    print(tok.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RUFrcCAx2hT",
        "outputId": "f5fccfe7-c705-4e9d-ad33-e0091c775b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nsubj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str = 'Army of Darkness is a 1992 American comedy horror film directed, co-written and co-edited by Sam Raimi, co-produced by Robert Tapert and Bruce Campbell and co-written by Ivan Raimi.'\n",
        "doc = nlp(str)\n",
        "print(p.get_entities(doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPeAjAlJ7K3a",
        "outputId": "af31896a-076d-480a-deb8-c58c0c361138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Army', 'American Ivan Raimi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "str = 'Army of Darkness is a 1992 American comedy horror film directed, co-written and co-edited by Sam Raimi, co-produced by Robert Tapert and Bruce Campbell and co-written by Ivan Raimi.'\n",
        "doc1 = nlp(str)\n",
        "for ent in doc1.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtiHBT7O8xaB",
        "outputId": "660740e4-99a4-4674-e7d1-88eda88feffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Army of Darkness 0 16 ORG\n",
            "1992 22 26 DATE\n",
            "American 27 35 NORP\n",
            "Sam Raimi 93 102 PERSON\n",
            "Robert Tapert 119 132 PERSON\n",
            "Bruce Campbell 137 151 PERSON\n",
            "Ivan Raimi 170 180 PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Training dataset"
      ],
      "metadata": {
        "id": "Tt3SRKpfvMjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SPARQLWrapper\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYe-RHNecZNQ",
        "outputId": "ed45286d-b39b-4d30-efd8-bbbf0c3c5c6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting rdflib>=6.1.1\n",
            "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (4.12.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 479 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=6.1.1->SPARQLWrapper) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=6.1.1->SPARQLWrapper) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate->rdflib>=6.1.1->SPARQLWrapper) (1.15.0)\n",
            "Installing collected packages: isodate, rdflib, SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-2.0.0 isodate-0.6.1 rdflib-6.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=open('file_4','rb')\n",
        "film_data=pickle.load(df)\n",
        "df.close()"
      ],
      "metadata": {
        "id": "s1CaB1_qclPA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "film_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMkmJYagugRC",
        "outputId": "76dfc592-0aec-42a9-927b-892313e909af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '45596993',\n",
              " 'revid': '39239779',\n",
              " 'url': 'https://en.wikipedia.org/wiki?curid=45596993',\n",
              " 'title': \"Scatter My Ashes at Bergdorf's\",\n",
              " 'text': '\"Scatter My Ashes at Bergdorf\\'s\" is a US 2013 documentary feature directed by Matthew Miele about the New York City luxury goods department store Bergdorf Goodman, situated on Fifth Avenue where it meets Grand Army Plaza. The film\\'s title is lifted from the caption of a 1990 Victoria Roberts cartoon that appeared in pages of \"The New Yorker\". The film features celebrities, store executives and employees, designers and customers testifying to their love of the place.\\nThe film opened at theatres on May 3, 2013.'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# title = film_data[4]['title'].split(\"(\")[0].strip()\n",
        "# film_data[4]['text'].find(title)\n",
        "d = {'hh':'hh'}\n",
        "if not 'director' in d.keys():\n",
        "  print('not in')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo-ZuqzAc4cK",
        "outputId": "b2226702-c006-42de-9291-71820ac8eab2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
        "films = []\n",
        "for film in film_data[:100]:\n",
        "  # build subject\n",
        "  full_name = film['title']\n",
        "  truncated_name = film['title'].split(\"(\")[0].strip()\n",
        "  text = film['text']\n",
        "  name_idx = text.find(truncated_name)\n",
        "  if name_idx == -1:\n",
        "    continue\n",
        "  # not sure the length of name should be full or trancated.\n",
        "  h = {\"name\": full_name, \"pos\":[name_idx, name_idx+len(truncated_name)]}\n",
        "\n",
        "  # find object\n",
        "  id = film['id']\n",
        "  sql = \"\"\"\n",
        "  SELECT DISTINCT ?director, ?starring\n",
        "  WHERE\n",
        "      {\n",
        "          ?film dbp:director ?director .\n",
        "          ?film dbp:starring ?starring .\n",
        "  \"\"\" + \"?film dbo:wikiPageID \" + id + \" .}\"\n",
        "  sparql.setQuery(sql)\n",
        "  sparql.setReturnFormat(JSON)\n",
        "  results = sparql.query().convert()\n",
        "  temp = results['results']['bindings']\n",
        "  if not temp:\n",
        "    continue\n",
        "  \n",
        "  # process the results of this film\n",
        "  directors = []\n",
        "  starrings = []\n",
        "  for item in temp:\n",
        "    # find all the directors of film\n",
        "    if not 'director' in item.keys():\n",
        "      continue\n",
        "    director = item['director']\n",
        "    t = director['type']\n",
        "    if t == 'literal':\n",
        "      director = director['value']\n",
        "    else:\n",
        "      director = director['value'].rsplit('/', 1)[-1].split('_')\n",
        "      director = \" \".join(director)\n",
        "    if director not in directors:\n",
        "      directors.append(director)\n",
        "\n",
        "    # find all the starrings of film\n",
        "    if not 'starring' in item.keys():\n",
        "      continue\n",
        "    starring = item['starring']\n",
        "    t = starring['type']\n",
        "    if t == 'literal':\n",
        "      starring = starring['value']\n",
        "    else:\n",
        "      starring = starring['value'].rsplit('/', 1)[-1].split('_')\n",
        "      starring = \" \".join(starring)\n",
        "    if starring not in starrings:\n",
        "      starrings.append(starring)\n",
        "\n",
        "  # build triplet\n",
        "  if not directors and not starrings:\n",
        "    continue\n",
        "  spo_list = []\n",
        "  # build the director - direct - film\n",
        "  for director in directors:\n",
        "    director_idx = text.find(director)\n",
        "    if not director_idx:\n",
        "      continue\n",
        "    t = {\"name\": director, \"pos\": [director_idx, director_idx + len(director)]}\n",
        "    triplet = {\"h\":h, \"t\":t, \"relation\": \"direct\"}\n",
        "    spo_list.append(triplet)\n",
        "  if not spo_list:\n",
        "    continue\n",
        "  # build the starring - act - film\n",
        "  for starring in starrings:\n",
        "    starring_idx = text.find(starring)\n",
        "    if not starring_idx:\n",
        "      continue\n",
        "    t = {\"name\": starring, \"pos\": [starring_idx, starring_idx + len(starring)]}\n",
        "    triplet = {\"h\":h, \"t\":t, \"relation\": \"act\"}\n",
        "    spo_list.append(triplet)\n",
        "\n",
        "  #new data\n",
        "  films.append({'id':id, 'text':text, 'spo_list': spo_list})\n",
        "#           "
      ],
      "metadata": {
        "id": "pSHgvVoiciUP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=open('training_data','wb')\n",
        "pickle.dump(films,df)\n",
        "df.close()"
      ],
      "metadata": {
        "id": "3Xqbs12alrd9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=open('training_data','rb')\n",
        "films=pickle.load(df)\n",
        "df.close()\n",
        "len(films)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iEKmynE4JKT",
        "outputId": "63958f05-b476-4888-fb65-2d98b1b105c8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}